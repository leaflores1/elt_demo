# ğŸ—ï¸ ELT Data Pipeline - Clientes y Ventas

Este proyecto implementa un pipeline ELT moderno, procesando datos crudos desde CSV hasta un modelo analÃ­tico final en PostgreSQL. Simula una arquitectura tipo Medallion (Bronze â†’ Silver â†’ Gold), comÃºn en plataformas como Databricks, Fabric y Snowflake.

---

## ğŸ“Œ Estructura del pipeline

| Capa   | DescripciÃ³n |
|--------|-------------|
| ğŸŸ« **Bronze** | Datos crudos cargados desde CSV |
| âš™ï¸ **Silver** | Transformaciones: limpieza, joins, enriquecimiento |
| ğŸŸ¡ **Gold**   | Tablas finales listas para BI o dashboards |

---

## ğŸ—‚ï¸ Estructura del proyecto

elt-data-pipeline-demo/
â”œâ”€â”€ data/ # Archivos CSV de entrada
â”œâ”€â”€ scripts/ # Script de carga a BRONZE
â”œâ”€â”€ sql/ # Scripts SQL para SILVER y GOLD
â”œâ”€â”€ dbt_project/ # (futuro) Proyecto dbt para transformaciones automatizadas
â”œâ”€â”€ .env # Variables de conexiÃ³n (no se sube)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸš€ TecnologÃ­as utilizadas

- PostgreSQL 17 + pgAdmin
- Python (pandas, SQLAlchemy)
- SQL (transformaciones manuales)
- Git + GitHub

---

## ğŸ§ª CÃ³mo correrlo

```bash
# 1. Clonar el repo
git clone https://github.com/leaflores1/elt_demo.git
cd elt_demo

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar .env
POSTGRES_USER=postgres
POSTGRES_PASSWORD=****
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=elt_demo

# 4. Cargar datos BRONZE
python scripts/load_bronze.py

# 5. Ejecutar SQL para SILVER y GOLD desde pgAdmin

 Aprendizajes
âœ” CÃ³mo construir un pipeline ELT completo desde cero
âœ” CÃ³mo aplicar transformaciones SQL con buenas prÃ¡cticas
âœ” CÃ³mo versionar y documentar un proyecto tÃ©cnico
âœ” Fundamentos reales para un futuro trabajo como Data Engineer

 PrÃ³ximos pasos
 Agregar dbt para modularizar Silver y Gold

 Automatizar con cron o Airflow

 Visualizar con dashboards (Plotly, Metabase o Power BI)
